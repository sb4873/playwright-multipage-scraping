{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas Tow Trucks\n",
    "\n",
    "We're going to scrape some [tow trucks in Texas](https://www.tdlr.texas.gov/tools_search/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One: Building a company list\n",
    "\n",
    "Search for businesses with the word **WRECK** in their names.\n",
    "\n",
    "* **Tip:** Start by scraping the first page to a dataframe, then expand to a loop that combines all of the pages. Finally combine all of the dataframes with `pd.concat`. You might find [this page helpful](https://jonathansoma.com/everything/scraping/pagination/), although the \"On an interactive site\" example uses Selenium instead of Playwright. You should be able to figure out how to change it!\n",
    "* **Tip:** You can't just do a `try`/`except`, because even if you ask for page 99999 it will always give you the last page again! Watch out that you don't get stuck in an infinite loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "\n",
    "# Create a new browser window\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://www.tdlr.texas.gov/tools_search/' request=<Request url='https://www.tdlr.texas.gov/tools_search/' method='GET'>>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading page\n",
    "await page.goto(\"https://www.tdlr.texas.gov/tools_search/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example, it would make a lot more sense to get results in the browser but I am trying to get used to this\n",
    "\n",
    "await page.locator('#namebutton').click()\n",
    "await page.locator('#namedata').fill('WRECK')\n",
    "await page.get_by_role('button').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Future exception was never retrieved\n",
      "future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>\n",
      "playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=Exception('Connection closed while reading from the driver')>\n",
      "Exception: Connection closed while reading from the driver\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 3\n",
      "Scraping page 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 5\n",
      "Scraping page 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 7\n",
      "Scraping page 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 9\n",
      "Scraping page 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 12\n",
      "Scraping page 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 14\n",
      "Scraping page 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 17\n",
      "Scraping page 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 21\n",
      "Scraping page 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 23\n",
      "Scraping page 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 26\n",
      "Scraping page 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 28\n",
      "Scraping page 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 31\n",
      "Scraping page 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 33\n",
      "Scraping page 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 35\n",
      "Scraping page 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 37\n",
      "Scraping page 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 39\n",
      "Scraping page 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n",
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/pstyf_r14hx35s64y_db5pq40000gn/T/ipykernel_303/1931143414.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(await page.content())\n"
     ]
    }
   ],
   "source": [
    "# scraping table to pandas df\n",
    "dataframes = []\n",
    "\n",
    "for page_num in range(1,42)  :\n",
    "    print(\"Scraping page\", page_num)\n",
    "    # Grab all the tables from the page\n",
    "    tables = pd.read_html(await page.content())\n",
    "\n",
    "    # In this case, we want the third one\n",
    "    df = tables[2]\n",
    "\n",
    "    # Add it to the list of dataframes\n",
    "    dataframes.append(df)\n",
    "\n",
    "    # Click the next number\n",
    "    if page_num < 41:\n",
    "            next_button_selector = 'a[href*=\"mccs_search_process.asp?page=\"]:text(\"[Next >>]\")'\n",
    "            await page.wait_for_selector(next_button_selector, state=\"visible\")\n",
    "            await page.click(next_button_selector, timeout=60000)\n",
    "    \n",
    "\n",
    "# Combine all the dataframes into one big dataframe\n",
    "df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer</td>\n",
       "      <td>DBA Name</td>\n",
       "      <td>TDLR Number</td>\n",
       "      <td>City</td>\n",
       "      <td>State</td>\n",
       "      <td>Zip code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALIBER WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006598046C (Insurance not applied !)</td>\n",
       "      <td>CHANNELVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>77530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC</td>\n",
       "      <td>006096604C</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC.</td>\n",
       "      <td>0612137VSF</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006529369C</td>\n",
       "      <td>SILSBEE</td>\n",
       "      <td>TX</td>\n",
       "      <td>77656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0593304VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0508198VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Customer</td>\n",
       "      <td>DBA Name</td>\n",
       "      <td>TDLR Number</td>\n",
       "      <td>City</td>\n",
       "      <td>State</td>\n",
       "      <td>Zip code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>XTREME WRECKER SERVICES INC.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0650507VSF</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>XTREME WRECKER SERVICES, INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006504760C</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0                              1  \\\n",
       "0                          Customer                       DBA Name   \n",
       "1       CALIBER WRECKER SERVICE LLC                            NaN   \n",
       "2        1ST CHOICE WRECKER SERVICE   1ST CHOICE PAINT & BODY, INC   \n",
       "3        1ST CHOICE WRECKER SERVICE  1ST CHOICE PAINT & BODY, INC.   \n",
       "4    1ST CHOICE WRECKER SERVICE LLC                            NaN   \n",
       "..                              ...                            ...   \n",
       "838        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "839        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "840                        Customer                       DBA Name   \n",
       "841    XTREME WRECKER SERVICES INC.                            NaN   \n",
       "842    XTREME WRECKER SERVICES, INC                            NaN   \n",
       "\n",
       "                                        2            3      4         5  \n",
       "0                             TDLR Number         City  State  Zip code  \n",
       "1    006598046C (Insurance not applied !)  CHANNELVIEW     TX     77530  \n",
       "2                              006096604C      TERRELL     TX     75160  \n",
       "3                              0612137VSF      TERRELL     TX     75160  \n",
       "4                              006529369C      SILSBEE     TX     77656  \n",
       "..                                    ...          ...    ...       ...  \n",
       "838                 0593304VSF (Expired!)         NASH     TX     75569  \n",
       "839                 0508198VSF (Expired!)         NASH     TX     75569  \n",
       "840                           TDLR Number         City  State  Zip code  \n",
       "841                            0650507VSF      BARSTOW     TX     79719  \n",
       "842                            006504760C      BARSTOW     TX     79719  \n",
       "\n",
       "[843 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "If you haven't already, rename the columns to be:\n",
    "    \n",
    "    * Customer\n",
    "    * DBA Name\n",
    "    * TDLR Number\n",
    "    * City\n",
    "    * State\n",
    "    * Zip code\n",
    "\n",
    "and remove all of the rows where the customer name is `Customer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>TDLR Number</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALIBER WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006598046C (Insurance not applied !)</td>\n",
       "      <td>CHANNELVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>77530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC</td>\n",
       "      <td>006096604C</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC.</td>\n",
       "      <td>0612137VSF</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006529369C</td>\n",
       "      <td>SILSBEE</td>\n",
       "      <td>TX</td>\n",
       "      <td>77656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0652937VSF</td>\n",
       "      <td>SILSBEE</td>\n",
       "      <td>TX</td>\n",
       "      <td>77656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0593304VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0508198VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Customer</td>\n",
       "      <td>DBA Name</td>\n",
       "      <td>TDLR Number</td>\n",
       "      <td>City</td>\n",
       "      <td>State</td>\n",
       "      <td>Zip code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>XTREME WRECKER SERVICES INC.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0650507VSF</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>XTREME WRECKER SERVICES, INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006504760C</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                          Customer                       DBA Name  \\\n",
       "1       CALIBER WRECKER SERVICE LLC                            NaN   \n",
       "2        1ST CHOICE WRECKER SERVICE   1ST CHOICE PAINT & BODY, INC   \n",
       "3        1ST CHOICE WRECKER SERVICE  1ST CHOICE PAINT & BODY, INC.   \n",
       "4    1ST CHOICE WRECKER SERVICE LLC                            NaN   \n",
       "5    1ST CHOICE WRECKER SERVICE LLC                            NaN   \n",
       "..                              ...                            ...   \n",
       "838        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "839        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "840                        Customer                       DBA Name   \n",
       "841    XTREME WRECKER SERVICES INC.                            NaN   \n",
       "842    XTREME WRECKER SERVICES, INC                            NaN   \n",
       "\n",
       "0                             TDLR Number         City  State  Zip code  \n",
       "1    006598046C (Insurance not applied !)  CHANNELVIEW     TX     77530  \n",
       "2                              006096604C      TERRELL     TX     75160  \n",
       "3                              0612137VSF      TERRELL     TX     75160  \n",
       "4                              006529369C      SILSBEE     TX     77656  \n",
       "5                              0652937VSF      SILSBEE     TX     77656  \n",
       "..                                    ...          ...    ...       ...  \n",
       "838                 0593304VSF (Expired!)         NASH     TX     75569  \n",
       "839                 0508198VSF (Expired!)         NASH     TX     75569  \n",
       "840                           TDLR Number         City  State  Zip code  \n",
       "841                            0650507VSF      BARSTOW     TX     79719  \n",
       "842                            006504760C      BARSTOW     TX     79719  \n",
       "\n",
       "[842 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>DBA Name</th>\n",
       "      <th>TDLR Number</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALIBER WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006598046C (Insurance not applied !)</td>\n",
       "      <td>CHANNELVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>77530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC</td>\n",
       "      <td>006096604C</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE</td>\n",
       "      <td>1ST CHOICE PAINT &amp; BODY, INC.</td>\n",
       "      <td>0612137VSF</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006529369C</td>\n",
       "      <td>SILSBEE</td>\n",
       "      <td>TX</td>\n",
       "      <td>77656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1ST CHOICE WRECKER SERVICE LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0652937VSF</td>\n",
       "      <td>SILSBEE</td>\n",
       "      <td>TX</td>\n",
       "      <td>77656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>005388553C</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0593304VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>WRIGHT'S WRECKER SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0508198VSF (Expired!)</td>\n",
       "      <td>NASH</td>\n",
       "      <td>TX</td>\n",
       "      <td>75569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>XTREME WRECKER SERVICES INC.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0650507VSF</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>XTREME WRECKER SERVICES, INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006504760C</td>\n",
       "      <td>BARSTOW</td>\n",
       "      <td>TX</td>\n",
       "      <td>79719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>802 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                          Customer                       DBA Name  \\\n",
       "1       CALIBER WRECKER SERVICE LLC                            NaN   \n",
       "2        1ST CHOICE WRECKER SERVICE   1ST CHOICE PAINT & BODY, INC   \n",
       "3        1ST CHOICE WRECKER SERVICE  1ST CHOICE PAINT & BODY, INC.   \n",
       "4    1ST CHOICE WRECKER SERVICE LLC                            NaN   \n",
       "5    1ST CHOICE WRECKER SERVICE LLC                            NaN   \n",
       "..                              ...                            ...   \n",
       "837        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "838        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "839        WRIGHT'S WRECKER SERVICE                            NaN   \n",
       "841    XTREME WRECKER SERVICES INC.                            NaN   \n",
       "842    XTREME WRECKER SERVICES, INC                            NaN   \n",
       "\n",
       "0                             TDLR Number         City State Zip code  \n",
       "1    006598046C (Insurance not applied !)  CHANNELVIEW    TX    77530  \n",
       "2                              006096604C      TERRELL    TX    75160  \n",
       "3                              0612137VSF      TERRELL    TX    75160  \n",
       "4                              006529369C      SILSBEE    TX    77656  \n",
       "5                              0652937VSF      SILSBEE    TX    77656  \n",
       "..                                    ...          ...   ...      ...  \n",
       "837                            005388553C         NASH    TX    75569  \n",
       "838                 0593304VSF (Expired!)         NASH    TX    75569  \n",
       "839                 0508198VSF (Expired!)         NASH    TX    75569  \n",
       "841                            0650507VSF      BARSTOW    TX    79719  \n",
       "842                            006504760C      BARSTOW    TX    79719  \n",
       "\n",
       "[802 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping values with boolean mask\n",
    "\n",
    "mask = df['Customer'] == 'Customer'\n",
    "df_clean = df[~mask]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as `wreckers.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('wreckers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two: Company info\n",
    "\n",
    "> You can use whatever tool you'd like for this, but form submission doesn't necessarily mean Playwright! If you want to go the `requests` route instead, feel free to [look at this page](https://jonathansoma.com/everything/scraping/pretending-to-be-a-browser/) about several ways to pretend to be a browser.\n",
    "\n",
    "## Step 1: Scraping one page\n",
    "\n",
    "Try searching from the [tools page](https://www.tdlr.texas.gov/tools_search/) for the TDLR Number `006556161C`. From the results page, scrape the:\n",
    "\n",
    "* Business name\n",
    "* Phone number\n",
    "* License status\n",
    "* Physical address\n",
    "\n",
    "And save the results into a dictionary. Also include `TDLR Number` in the dictionary. **Print the dictionary**.\n",
    "\n",
    "> ***Tip:** It's best if each item has its own key, but **it's fine to pull \"larger\" sections of the page and split them up in pandas later on***\n",
    ">\n",
    "> ***Tip:** Be sure you don't forget to include `TDLR Number` in the dictionary!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### searching the TDLR Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new browser window\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://www.tdlr.texas.gov/tools_search/' request=<Request url='https://www.tdlr.texas.gov/tools_search/' method='GET'>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load the search page\n",
    "await page.goto('https://www.tdlr.texas.gov/tools_search/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.locator('#mcrbutton').click()\n",
    "await page.locator('#mcrdata').fill('006556161C')\n",
    "await page.get_by_role('button').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scaraping the relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business Name': 'DIRTY SOUTH TRANSPORT AND RECOVERY, LLC ',\n",
       " 'Phone': '713-259-5445',\n",
       " 'License No': '006556161',\n",
       " 'License Status': '(Active)',\n",
       " 'Physical Address': '11053 LORETTA LN, PLANTERSVILLE,TX.77363'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tldr = await page.content()\n",
    "doc_tldr = BeautifulSoup(html_tldr)\n",
    "\n",
    "# lets get all 'tables'\n",
    "all_tables = doc_tldr.select('table')\n",
    "\n",
    "# table[3] for name and phone no.\n",
    "table_3 = all_tables[3]\n",
    "elements_3 = table_3.select('td')\n",
    "\n",
    "# cleaning elements\n",
    "name = elements_3[2].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "phone = elements_3[8].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "\n",
    "# table[4] for other details\n",
    "table_4 = all_tables[4]\n",
    "elements_4 = table_4.select('td')\n",
    "\n",
    "status = elements_4[1].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "tdlr = elements_4[2].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "\n",
    "# Define a regular expression pattern to extract the no. and status\n",
    "pattern = r'(\\d+)[^\\(]+(\\(.*\\))'\n",
    "\n",
    "# Use re.match to find the matches in the text\n",
    "match = re.match(pattern, tdlr)\n",
    "number = match.group(1).strip()\n",
    "status = match.group(2).strip()\n",
    "\n",
    "# finally the address\n",
    "\n",
    "# address_int = elements_4[3].text.split('\\n')[1].replace('\\xa0', ' ').lstrip()\n",
    "address_string_list = [every.replace('\\xa0', '').strip() for every in elements_4[3].text.split('\\n')[12:14]]\n",
    "\n",
    "address = f\"{address_string_list[0]}, {address_string_list[1]}\"\n",
    "\n",
    "# Now lets create a dictionary\n",
    "\n",
    "dict_tdlr = {\n",
    "    'Business Name': name,\n",
    "    'Phone': phone,\n",
    "    'License No': number,\n",
    "    'License Status': status,\n",
    "    'Physical Address' : address\n",
    "}\n",
    "\n",
    "dict_tdlr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Move into one cell\n",
    "\n",
    "Move the code above all into one cell that relies on the variable `tdlr_number`.\n",
    "\n",
    "Add the code below to the page and confirm that it displays the data for the correct result.\n",
    "\n",
    "```python\n",
    "tdlr_number = '0654479VSF'\n",
    "```\n",
    "\n",
    "Confirm that the information is correct. Did it not work out? Go back and edit your selectors, or be a little broader in the parts of the page you sweep up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new browser window\n",
    "page = await browser.new_page()\n",
    "# load the search page\n",
    "await page.goto('https://www.tdlr.texas.gov/tools_search/')\n",
    "# search the tdlr\n",
    "await page.locator('#mcrbutton').click()\n",
    "await page.locator('#mcrdata').fill('006556161C')\n",
    "await page.get_by_role('button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business Name': 'DIRTY SOUTH TRANSPORT AND RECOVERY, LLC',\n",
       " 'Phone': '713-259-5445',\n",
       " 'License No': '006556161',\n",
       " 'License Status': '(Active)',\n",
       " 'Physical Address': '11053 LORETTA LN, PLANTERSVILLE,TX.77363'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tldr = await page.content()\n",
    "doc_tldr = BeautifulSoup(html_tldr)\n",
    "\n",
    "# lets get all 'tables'\n",
    "all_tables = doc_tldr.select('table')\n",
    "\n",
    "# # table[3] for name and phone no.\n",
    "# table_3 = all_tables[3]\n",
    "# elements_3 = table_3.select('td')\n",
    "\n",
    "# # cleaning elements\n",
    "\n",
    "# name = elements_3[2].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "# phone = elements_3[8].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "\n",
    "# table[4] for other details\n",
    "table_4 = all_tables[4]\n",
    "elements_4 = table_4.select('td')\n",
    "\n",
    "status = elements_4[1].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "tdlr = elements_4[2].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "\n",
    "# Define a regular expression pattern to extract the no. and status\n",
    "pattern = r'(\\d+)[^\\(]+(\\(.*\\))'\n",
    "\n",
    "# Use re.match to find the matches in the text\n",
    "match = re.match(pattern, tdlr)\n",
    "number = match.group(1).strip()\n",
    "status = match.group(2).strip()\n",
    "\n",
    "# the address\n",
    "\n",
    "# address_int = elements_4[3].text.split('\\n')[1].replace('\\xa0', ' ').lstrip()\n",
    "address_string_list = [every.replace('\\xa0', '').strip() for every in elements_4[3].text.split('\\n')[12:14]]\n",
    "\n",
    "address = f\"{address_string_list[0]}, {address_string_list[1]}\"\n",
    "\n",
    "# name and phone ( I used chatGPT here to change the code after my initial one failed)\n",
    "\n",
    "# Extract all text\n",
    "all_text = doc_tldr.get_text(separator=' ', strip=True)\n",
    "\n",
    "# Identify relevant information based on context\n",
    "name_index = all_text.index('Name:')\n",
    "name = all_text[name_index + len('Name:'):].split('DBA:')[0].strip()\n",
    "\n",
    "phone_index = all_text.index('Phone:')\n",
    "phone = all_text[phone_index + len('Phone:'):].split('Certificate Information:')[0].strip()\n",
    "\n",
    "# Now lets create a dictionary\n",
    "\n",
    "dict_tdlr = {\n",
    "    'Business Name': name,\n",
    "    'Phone': phone,\n",
    "    'License No': number,\n",
    "    'License Status': status,\n",
    "    'Physical Address' : address\n",
    "}\n",
    "\n",
    "dict_tdlr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Scraping many pages\n",
    "\n",
    "Using pandas, read in `trucks-subset.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TDLR Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006565540C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0654479VSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006564940C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TDLR Number\n",
       "0  006565540C\n",
       "1  0654479VSF\n",
       "2  006564940C"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trucks_subset = pd.read_csv('trucks-subset.csv')\n",
    "df_trucks_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape every single row, creating a list of dictionaries from the scraped data.\n",
    "\n",
    "You should never use for loops with pandas *except when working with Playwright*. To use loops in pandas you'll make use of `.iterrows()`.\n",
    "\n",
    "The code below loops through a dataframe called `df` and prints out the `address` column.\n",
    "\n",
    "```python\n",
    "for index, row in df.iterrows():\n",
    "    print(row['address'])\n",
    "```\n",
    "\n",
    "You'll adapt this code to use your dataframe, and combine it with the scraping code you wrote above.\n",
    "\n",
    "> ***Tip:** This is like what we did for the townships in class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['006565540C', '0654479VSF', '006564940C']\n"
     ]
    }
   ],
   "source": [
    "lic_nums = []\n",
    "for index, row in df_trucks_subset.iterrows():\n",
    "    lic_nums.append(row['TDLR Number'])\n",
    "print(lic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = []\n",
    "for num in lic_nums :\n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch(headless=False)\n",
    "    # Create a new browser window\n",
    "    page = await browser.new_page()\n",
    "    # load the search page\n",
    "    await page.goto('https://www.tdlr.texas.gov/tools_search/')\n",
    "    # search the tdlr\n",
    "    await page.locator('#mcrbutton').click()\n",
    "    await page.locator('#mcrdata').fill(num)\n",
    "    await page.get_by_role('button').click()\n",
    "    html_tldr = await page.content()\n",
    "    doc_tldr = BeautifulSoup(html_tldr)\n",
    "    \n",
    "    # CREATE THE DICTIONARY\n",
    "    \n",
    "    # lets get all 'tables'\n",
    "    all_tables = doc_tldr.select('table')\n",
    "    \n",
    "    # table[4] for other details\n",
    "    table_4 = all_tables[4]\n",
    "    elements_4 = table_4.select('td')\n",
    "    \n",
    "    status = elements_4[1].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "    tdlr = elements_4[2].text.split(':')[1].replace('\\xa0', ' ').lstrip()\n",
    "    \n",
    "    # Define a regular expression pattern to extract the no. and status\n",
    "    pattern = r'(\\d+)[^\\(]+(\\(.*\\))'\n",
    "    \n",
    "    # Use re.match to find the matches in the text\n",
    "    match = re.match(pattern, tdlr)\n",
    "    number = match.group(1).strip()\n",
    "    status = match.group(2).strip()\n",
    "    \n",
    "    # the address\n",
    "    \n",
    "    # address_int = elements_4[3].text.split('\\n')[1].replace('\\xa0', ' ').lstrip()\n",
    "    address_string_list = [every.replace('\\xa0', '').strip() for every in elements_4[3].text.split('\\n')[12:14]]\n",
    "    \n",
    "    address = f\"{address_string_list[0]}, {address_string_list[1]}\"\n",
    "    \n",
    "    # name and phone ( I used chatGPT here to change the code after my initial one failed)\n",
    "    \n",
    "    # Extract all text\n",
    "    all_text = doc_tldr.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    # Identify relevant information based on context\n",
    "    name_index = all_text.index('Name:')\n",
    "    name = all_text[name_index + len('Name:'):].split('DBA:')[0].strip()\n",
    "    \n",
    "    phone_index = all_text.index('Phone:')\n",
    "    phone = all_text[phone_index + len('Phone:'):].split('Certificate Information:')[0].strip()\n",
    "    \n",
    "    # Now lets create a dictionary\n",
    "    \n",
    "    dict_tdlr = {\n",
    "        'Business Name': name,\n",
    "        'Phone': phone,\n",
    "        'License No': number,\n",
    "        'License Status': status,\n",
    "        'Physical Address' : address\n",
    "    }\n",
    "    \n",
    "    dict_tdlr\n",
    "    all_dict.append(dict_tdlr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Business Name': 'H & A TOWING LLC', 'Phone': '512-999-8883', 'License No': '006565540', 'License Status': '(Expired)', 'Physical Address': '11710 JOSEPH CLAYTON DR, AUSTIN,TX.78753'}, {'Business Name': '24/7TOWINGANDRECOVERYLLC', 'Phone': '4325576733', 'License No': '0654479', 'License Status': '(Active)', 'Physical Address': '3601 N COUNTY ROAD 1148, MIDLAND,TX.79705'}, {'Business Name': 'A&NTOWINGLLC', 'Phone': '2106678546', 'License No': '006564940', 'License Status': '(Active)', 'Physical Address': '1341  GAYLE LN, POTEET,TX.78065'}]\n"
     ]
    }
   ],
   "source": [
    "print(all_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your dataframe as `data-uncleaned.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(all_dict)\n",
    "df_all.to_csv('data-uncleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning your data\n",
    "\n",
    "## Re-open the `data-uncleaned.csv` file\n",
    "\n",
    "You probably want to set `pd.options.display.max_colwidth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finally = pd.read_csv('data-uncleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean it up!\n",
    "\n",
    "Make sure there are columns for\n",
    "\n",
    "- Business name\n",
    "- Phone number\n",
    "- License status\n",
    "- Physical address\n",
    "\n",
    "And drop all of the other columns (The easiest way is to use `df = df.drop(columns=[...])`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not dropping the license no. coz we need it later (or so I thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>License Status</th>\n",
       "      <th>Physical Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H &amp; A TOWING LLC</td>\n",
       "      <td>512-999-8883</td>\n",
       "      <td>(Expired)</td>\n",
       "      <td>11710 JOSEPH CLAYTON DR, AUSTIN,TX.78753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/7TOWINGANDRECOVERYLLC</td>\n",
       "      <td>4325576733</td>\n",
       "      <td>(Active)</td>\n",
       "      <td>3601 N COUNTY ROAD 1148, MIDLAND,TX.79705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A&amp;NTOWINGLLC</td>\n",
       "      <td>2106678546</td>\n",
       "      <td>(Active)</td>\n",
       "      <td>1341  GAYLE LN, POTEET,TX.78065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Business Name         Phone License Status  \\\n",
       "0          H & A TOWING LLC  512-999-8883      (Expired)   \n",
       "1  24/7TOWINGANDRECOVERYLLC    4325576733       (Active)   \n",
       "2              A&NTOWINGLLC    2106678546       (Active)   \n",
       "\n",
       "                            Physical Address  \n",
       "0   11710 JOSEPH CLAYTON DR, AUSTIN,TX.78753  \n",
       "1  3601 N COUNTY ROAD 1148, MIDLAND,TX.79705  \n",
       "2            1341  GAYLE LN, POTEET,TX.78065  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with the original CSV file\n",
    "\n",
    "To combine dataframes based on indexes, you use `df.join(other_df)`. If you'd prefer to match by columns, you could also use `df.merge(other_df, left_on='...', right_on='...')` and tell it the two columns that match between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>License No</th>\n",
       "      <th>License Status</th>\n",
       "      <th>Physical Address</th>\n",
       "      <th>TDLR Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H &amp; A TOWING LLC</td>\n",
       "      <td>512-999-8883</td>\n",
       "      <td>6565540</td>\n",
       "      <td>(Expired)</td>\n",
       "      <td>11710 JOSEPH CLAYTON DR, AUSTIN,TX.78753</td>\n",
       "      <td>006565540C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/7TOWINGANDRECOVERYLLC</td>\n",
       "      <td>4325576733</td>\n",
       "      <td>654479</td>\n",
       "      <td>(Active)</td>\n",
       "      <td>3601 N COUNTY ROAD 1148, MIDLAND,TX.79705</td>\n",
       "      <td>0654479VSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A&amp;NTOWINGLLC</td>\n",
       "      <td>2106678546</td>\n",
       "      <td>6564940</td>\n",
       "      <td>(Active)</td>\n",
       "      <td>1341  GAYLE LN, POTEET,TX.78065</td>\n",
       "      <td>006564940C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Business Name         Phone  License No License Status  \\\n",
       "0          H & A TOWING LLC  512-999-8883     6565540      (Expired)   \n",
       "1  24/7TOWINGANDRECOVERYLLC    4325576733      654479       (Active)   \n",
       "2              A&NTOWINGLLC    2106678546     6564940       (Active)   \n",
       "\n",
       "                            Physical Address TDLR Number  \n",
       "0   11710 JOSEPH CLAYTON DR, AUSTIN,TX.78753  006565540C  \n",
       "1  3601 N COUNTY ROAD 1148, MIDLAND,TX.79705  0654479VSF  \n",
       "2            1341  GAYLE LN, POTEET,TX.78065  006564940C  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finally.join(df_trucks_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finally.to_csv('tow_trucks_are_the_worst.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
